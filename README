# Breast Cancer Histology Analysis Pipeline

This project provides tools for segmenting nuclei in breast cancer histology images and a pipeline for extracting features and training a classification model.

## Project Structure

```text
.
├── pipeline_final.ipynb # Main ML pipeline (feature extraction -> SVM -> evaluation)

├── segmentation_tuner.py # Gradio UI for tuning segmentation parameters
├── raw/ # Data directory (needs to be populated)
│ ├── benign/
│ └── malignant/
├── requirements.txt # Python package dependencies
└── README.md # This file
```

## Setup Instructions

1.  **Clone the Repository (if applicable):**
    If this project is in a Git repository, clone it:

    ```bash
    git clone <repository_url>
    cd <repository_directory_name>
    ```

2.  **Create a Virtual Environment (Recommended):**
    It's highly recommended to use a virtual environment to manage dependencies.

    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    Install the required Python packages using pip:

    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up `ipywidgets` for Jupyter (Crucial for `pipeline_final.ipynb`):**
    If you encounter issues with progress bars (`tqdm.notebook`) in `pipeline_final.ipynb`, ensure `ipywidgets` is correctly configured for your Jupyter environment:

    - **For Jupyter Notebook:**
      ```bash
      jupyter nbextension enable --py widgetsnbextension --sys-prefix
      ```
    - **For JupyterLab:**
      You might need to install `jupyterlab-widgets` and potentially rebuild JupyterLab:
      `bash
      pip install jupyterlab-widgets
      jupyter labextension develop --overwrite widgetsnbextension

    # If prompted, or if widgets still don't work:

    # jupyter lab build

    `
    Restart your Jupyter server/kernel after these steps.

5.  **Dataset Preparation:**
    - You should have received a ZIP file containing the image dataset (approximately 4GB).
    - Create a directory named `raw` in the root of this project directory if it doesn't already exist.
    - Extract the contents of the dataset ZIP file directly into this `raw` folder.
    - The expected structure within the `raw` folder is:
      ```
      raw/
      ├── benign/
      │   └── SOB/
      │       ├── adenosis/
      │       │   └── <patient_slide_id>/
      │       │       ├── 40X/
      │       │       │   └── <image_file.png>
      │       │       ├── 100X/
      │       │       └── ...
      │       └── ... (other benign subtypes)
      └── malignant/
          └── SOB/
              ├── ductal_carcinoma/
              │   └── <patient_slide_id>/
              │       ├── 40X/
              │       └── ...
              └── ... (other malignant subtypes)
      ```
    - **Important:** The scripts rely on this directory structure and the naming convention of the image files to determine magnification and patient/slide IDs.

## Usage

There are two main components to this project:

### A. Interactive Segmentation Parameter Tuner (`segmentation_tuner.py`)

This Gradio application allows you to visually inspect and fine-tune the parameters for the advanced nuclei segmentation algorithm.

1.  **Launch the Tuner:**
    Navigate to the project's root directory in your terminal (where `segmentation_tuner.py` is located) and run:

    ```bash
    python segmentation_tuner.py
    ```

    This will start a local web server, and a URL (usually `http://127.0.0.1:7860` or similar) will be printed in the terminal. Open this URL in your web browser.

2.  **Using the Tuner UI:**
    - **Left Panel (Controls):**
      - **Select Patient/Slide ID:** Use the dropdown to choose a patient/slide. Images for all available magnifications (40X, 100X, 200X, 400X) for this ID will be processed and displayed.
      - **Segmentation Parameters:** Adjust the sliders and input fields for:
        - Global Settings (contrast, thresholding, watershed usage).
        - Morphological Operations (kernel sizes, iterations).
        - Magnification-Specific Filters: For each magnification (40X, 100X, 200X, 400X), you can set `Min/Max Area`, `Min Circularity` for contours, and the `Watershed Seed Ratio`. The UI will apply the settings relevant to the magnification of the image being processed within each tab.
      - **Configuration Management:**
        - "Current Live Configuration (JSON)": Shows the parameters as currently set by the UI controls. This updates live.
        - "Saved Configuration": Displays the configuration you last "saved".
        - "Save Current Settings to 'Saved Config' Display": Click this button when you are satisfied with the current live settings. It will copy the "Live Config" to the "Saved Config" display.
    - **Right Panel (Segmentation Results):**
      - This panel has **Tabs** for each magnification (40X, 100X, 200X, 400X).
      - Within each tab, you will see:
        - The original image for that magnification.
        - The final segmented image with nuclei contours overlaid.
        - A plot showing the intermediate steps of the segmentation process.
    - **Tuning Process:**
      1.  Select a Patient/Slide ID.
      2.  Observe the segmentation results across all magnification tabs.
      3.  Adjust parameters in the left panel. The displays in the right panel will update automatically.
      4.  Iterate by selecting different Patient/Slide IDs and refining parameters until you achieve satisfactory segmentation across various image types and magnifications.
      5.  Once happy, click "Save Current Settings to 'Saved Config' Display".
      6.  **Copy the JSON content from the "Saved Configuration" text box.** This is the configuration you will use in the main pipeline.

### B. Main Machine Learning Pipeline (`pipeline_final.ipynb`)

This Jupyter Notebook runs the full workflow: patient-level data splitting, feature extraction using the advanced segmentation, SVM model training, and evaluation.

1.  **Launch Jupyter:**
    Start Jupyter Notebook or JupyterLab from your project's root directory:

    ```bash
    jupyter notebook
    # or
    jupyter lab
    ```

    Open `pipeline_final.ipynb` from the Jupyter interface.

2.  **Update Segmentation Configuration:**

    - Navigate to **Cell [4] (Configuration)** in the notebook.
    - Locate the `SEGMENTATION_CONFIG` dictionary.
    - **Paste the JSON configuration you copied from the `segmentation_tuner.py` UI** into this dictionary, ensuring it's valid Python dictionary syntax. This step is crucial for the pipeline to use your optimally tuned segmentation parameters.

3.  **Run the Notebook:**

    - Execute all cells in the notebook sequentially (e.g., "Run" -> "Run All Cells").
    - The notebook will:
      - Scan the `raw` directory for images.
      - Perform a patient-level split of the data into training and testing sets.
      - Extract features from images in the training set using the advanced segmentation.
      - Train an SVM classifier.
      - Extract features from images in the testing set.
      - Evaluate the SVM model on the test set and display metrics (accuracy, classification report, confusion matrix, ROC AUC).

4.  **Review Results:**
    - Analyze the output, particularly the model evaluation metrics in Section 9 and the summary in Section 10.

## Notes

- The path to the data directory (`ROOT_DATA_DIR`) is set dynamically in both `segmentation_tuner.py` and `pipeline_final.ipynb` to be `./raw/` relative to the script/notebook's location. Ensure the `raw` folder is in the same directory as these files.
- The quality of nuclei segmentation significantly impacts feature extraction and, consequently, model performance. Spend adequate time tuning the parameters using `segmentation_tuner.py`.

## Troubleshooting

- **`ImportError: IProgress not found` in `pipeline_final.ipynb`:** Ensure `ipywidgets` is installed and enabled for your Jupyter environment (see Setup Step 4). As a fallback, you can change `from tqdm.notebook import tqdm` to `from tqdm import tqdm` in Cell [2] of the notebook.
- **`FileNotFoundError` or "No images found":** Double-check that `ROOT_DATA_DIR` is correctly pointing to your `raw` data folder and that the folder is populated with the dataset in the expected structure.
- **Slow UI Updates in `segmentation_tuner.py`:** If processing all magnifications for a patient ID is too slow for live updates, you might consider adding an "Apply Parameters" button to trigger reprocessing manually. This would involve changing `.change(...)` events to be triggered by a button click.
